### <span style="color:#4caf50;">Sprawdzian krzy偶owy (Cross-Validation)</span> 
> Proces ten polega na podzieleniu zbioru danych na <span style="color:#ff5722;">*k*</span> r贸wnych czci (*folds*).

1. Model jest trenowany na <span style="color:#ff5722;">*k-1*</span> czciach, a testowany na jednej z pozostaych.
2. Procedura jest powtarzana <span style="color:#ff5722;">*k*</span> razy, za ka偶dym razem wybierajc inny podzbi贸r jako zbi贸r testowy.
3. Wynik kocowy to rednia ze wszystkich <span style="color:#ff5722;">*k*</span> iteracji.

- Zmniejsza ryzyko <span style="color:#d32f2f;">**overfittingu**</span> poprzez sprawdzanie modelu na r贸偶nych partiach danych.

W Scikit-learn implementuje to funkcja `cross_val_score` z opcj `KFold` do okrelenia liczby podzia贸w (k).

---

### **<span style="color:#1e88e5;">Przeszukiwanie siatki (Grid Search)</span>** 

**GridSearchCV** to metoda doboru hiperparametr贸w w `Scikit-learn`, kt贸ra testuje wszystkie kombinacje zadanych wartoci hiperparametr贸w, aby znale藕 najlepsz.

### <span style="color:#1e88e5;">Jak dziaa GridSearchCV?</span> 锔
1. **Zdefiniowanie siatki**: U偶ytkownik definiuje wartoci hiperparametr贸w. Przykad dla `RandomForestClassifier`:
   - `n_estimators`: [100, 200, 300]
   - `max_depth`: [5, 10, 15]
   
2. **Przegld kombinacji**: Model trenowany jest dla ka偶dej kombinacji hiperparametr贸w, a wydajno oceniana na zbiorze walidacyjnym. U偶ywa si walidacji krzy偶owej (`cv`).

3. **Ocena**: Wyniki dla ka偶dej kombinacji s mierzone za pomoc zdefiniowanej metryki, np. `accuracy` czy `F1-score`.

4. **Wyb贸r najlepszego zestawu**: Po przetestowaniu wszystkich kombinacji, zestaw hiperparametr贸w o najlepszym wyniku zostaje wybrany.

W Scikit-learn implementowane przez `GridSearchCV`.

```python
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

# Zaadowanie danych
data = load_iris()
X, y = data.data, data.target

# Podzia na dane treningowe i testowe
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Definicja hiperparametr贸w
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15]
}

# Model Random Forest
model = RandomForestClassifier()

# Grid Search z walidacj krzy偶ow (5-fold) na danych treningowych
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Najlepsze parametry
print(f"Najlepsze parametry: {grid_search.best_params_}")

# Ocena na zbiorze testowym
test_accuracy = grid_search.score(X_test, y_test)
print(f"Dokadno na zbiorze testowym: {test_accuracy:.2f}")

#Wynik
#Najlepsze parametry: {'max_depth': 10, 'n_estimators': 300}
#Dokadno na zbiorze testowym: 0.98

```
### <span style="color:#1e88e5;">Przeszukiwanie losowe (Random Search)</span> 

**RandomizedSearchCV** to alternatywa dla Grid Search, kt贸ra nie przeszukuje wszystkich mo偶liwych kombinacji, a jedynie losowo wybrane pr贸bki z przestrzeni hiperparametr贸w.

### <span style="color:#1e88e5;">Jak dziaa RandomizedSearchCV?</span> 锔
1. **Zdefiniowanie zakresu**: U偶ytkownik definiuje zakresy wartoci dla hiperparametr贸w.
2. **Losowy wyb贸r**: Algorytm losowo wybiera kombinacje wartoci do przetestowania (zamiast sprawdza wszystkie).
3. **Ocena**: Kombinacje oceniane s na zbiorze walidacyjnym, a wyniki mierzone wedug wybranej metryki.
4. **Wyb贸r najlepszego zestawu**: Najlepsza kombinacja zostaje wybrana do trenowania finalnego modelu.

### <span style="color:#4caf50;">Zalety Random Search:</span>
- **Szybko**: Przeszukiwanie losowe jest szybsze ni偶 Grid Search, szczeg贸lnie przy du偶ej liczbie parametr贸w.

W Scikit-learn implementowane przez `RandomizedSearchCV`.

```python
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from scipy.stats import randint
from sklearn.metrics import accuracy_score

# Zaadowanie danych
data = load_iris()
X, y = data.data, data.target

# Podzia na dane treningowe i testowe
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Definicja zakres贸w dla hiperparametr贸w
param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(5, 20)
}

# Model Random Forest
model = RandomForestClassifier()

# Random Search z walidacj krzy偶ow (5-fold), 10 losowych pr贸bek
random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)
random_search.fit(X_train, y_train)

# Najlepsze parametry
print(f"Najlepsze parametry: {random_search.best_params_}")

# Ocena na zbiorze testowym
y_pred = random_search.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
print(f"Dokadno na zbiorze testowym: {test_accuracy:.2f}")

```
---

### <span style="color:#ff5722;">Przykad </span> dla modelu Random Forest:
#### Grid Search:
- `n_estimators`: [100, 200, 300]
- `max_depth`: [5, 10, 15]  
Przeszukuje wszystkie mo偶liwe kombinacje.

#### Random Search:
- `n_estimators`: od 100 do 500
- `max_depth`: od 5 do 20  
Losowo wybiera pr贸bki z przestrzeni tych wartoci do testowania.

### <span style="color:#4caf50;">Etapy analizy bd贸w</span> 

---

### <span style="color:#1e88e5;"> Macierz pomyek (Confusion Matrix)</span> 

 Pozwala zobaczy, jak model klasyfikuje pr贸bki: ile razy poprawnie przewiduje dan klas, a ile razy pomyli si, klasyfikujc pr贸bki do innych klas.
 
>[!important]
> Elementy Confusion Matrix
>- **True Positives (TP)**: poprawne pozytywne predykcje.
>- **True Negatives (TN)**: poprawne negatywne predykcje.
>- **False Positives (FP)**: bdne predykcje klasy pozytywnej (faszywe alarmy).
>- **False Negatives (FN)**: bdne predykcje klasy negatywnej (pominicia).

#### Przykad macierzy pomyek (dla klasyfikacji binarnej):
```
            Predicted Positive   Predicted Negative
Actual Pos          50                    10
Actual Neg          5                     35

- Model poprawnie przewidzia 50 pozytywnych przypadk贸w (TP) i 35 negatywnych (TN).
- 5 negatywnych przypadk贸w zostao bdnie przewidzianych jako pozytywne (FP).
- 10 pozytywnych przypadk贸w zostao bdnie sklasyfikowanych jako negatywne (FN).
```

```python
from sklearn.metrics import confusion_matrix, classification_report y_true = [0, 0, 1, 1, 0, 1, 0, 1, 1, 1] # rzeczywiste etykiety 
y_pred = [0, 1, 1, 1, 0, 0, 0, 1, 1, 1] # przewidziane etykiety 

# Macierz pomyek 
cm = confusion_matrix(y_true, y_pred) print("Macierz pomyek:") print(cm) 

print("\nRaport klasyfikacji:") 
print(classification_report(y_true, y_pred))


#Macierz pomyek:
#[[3 1]
 #[1 5]]

#Raport klasyfikacji:
#             precision    recall  f1-score   support

#           0       0.75      0.75      0.75         4
#          1       0.83      0.83      0.83         6

#    accuracy                           0.80        10
#   macro avg       0.79      0.79      0.79        10
#weighted avg       0.80      0.80      0.80        10

```

# Link do Jupyter Notebook

wiczenia dla tego tematu zostay zebrane [tutaj](https://github.com/KoloNaukowe-RAI/Kurs-Machine-Learning/blob/main/Tasks/Tasks08_Metryki_Oceny_Modelu.ipynb).
# Co dalej?

Kliknij [[Index|tutaj]], aby wr贸ci do strony g贸wnej kursu.

