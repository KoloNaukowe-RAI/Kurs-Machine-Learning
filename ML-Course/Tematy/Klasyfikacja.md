W zbiorze danych wystpuje 70 tys. obraz贸w, a ka偶dy z nich opisany jest 784 cechami. Wynika to faktu, 偶e ka偶dy obraz ma 28x28 pikseli, a ka偶da cecha opisuje nat偶enie szaroci danego piksela
(przyjmuje warto od 0 do 255)

```python
import tensorflow as tf  
import matplotlib.pyplot as plt  
  
mnist = tf.keras.datasets.mnist  
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  
  
X = train_images.reshape(60000, 28*28)   
y = train_labels  
  
print("Rozmiar danych X (zbi贸r uczcy):", X.shape)  
print("Rozmiar danych y (etykiety):", y.shape)  
  
def plot_digit(image):  
    image = image.reshape(28, 28) 
    plt.imshow(image, cmap='binary')  
    plt.axis('off')  
    plt.show()  
  
# Wywietlenie przykad贸w  
for i in range(5):  
    print(f"Przykad {i + 1}: Cyfra {y[i]}")  
    plot_digit(X[i])  
  
# Podzia na zbiory: uczcy (60 tys.) i testowy (10 tys.)  
X_train = X[:60000]  
y_train = y[:60000]  
  
X_test = test_images.reshape(10000, 28*28)  
y_test = test_labels  
  
print("Rozmiar danych uczcych X_train:", X_train.shape)  
print("Rozmiar danych testowych X_test:", X_test.shape)

```

Przykadowe dane przedstawione s poni偶ej:
![[picture_1.png]]
![[picture_4.png]]
![[picture_9.png]]

>Rozmiar danych X (zbi贸r uczcy): (60000, 784)
>Rozmiar danych y (etykiety): (60000,)

W powy偶szym przykadzie aby sprawdzi jak wygldaj cyfry przechowywane w zestawie danych wybralimy wektor cech danej pr贸bki i przeksztacilimy go w macierz o rozmiarze 28x28, kt贸r wywietlilimy za pomoc funkcji imshow(). Do uzyskania mapy w skali szaroci wykorzystalimy parametr cmap='binary'. 


1. Uczenie klasyfikatora binarnego 
Na pocztku uprocimy sobie zadanie i spr贸bujemy identyfikowa jedn cyfr na przykad 5. Jest to przykad klasyfikatora binarnego, kt贸ry ma zdolno do rozpoznawania jednej z dw贸ch klas: pitek i niepitek. Zadanie to rozpoczniemy od stworzenia wektor贸w docelowych dla tego zadania klasyfikujcego.
```python
X_test = test_images.reshape(10000, 28 * 28)    
y_test = test_labels  
  
y_train_binary = (y_train == 5).astype(np.int8)  # 1 dla cyfry 5, 0 dla innych  
y_test_binary = (y_test == 5).astype(np.int8)  
  

sgd_clf = SGDClassifier(random_state=42)  
sgd_clf.fit(X_train, y_train_binary)  
  

y_pred = sgd_clf.predict(X_test)  
  
accuracy = accuracy_score(y_test_binary, y_pred)  
print(f'Dokadno klasyfikatora: {accuracy:.2f}')  
  
print("Przykadowe predykcje (1 oznacza cyfr 5):")  
print("Predykcje:", y_pred[:10])  
print("Prawdziwe etykiety:", y_test_binary[:10])  
  
```
>Dokadno klasyfikatora: 0.95
>Przykadowe predykcje (1 oznacza cyfr 5):
>Predykcje: [0 0 0 0 0 0 0 0 0 0]
>Prawdziwe etykiety: [0 0 0 0 0 0 0 0 1 0]

W przykadzie wykorzystano klasyfikator stochastycznego spadku wzdu偶 gradientu w tym celu skorzystano z klasy SGDClassifier. Klasyfikator ten sprawdza si w przypadku przetwarzania bardzo du偶ych zbior贸w danych. Wynika to faktu, 偶e klasyfikator ten przetwarza poszczeg贸lne przykady uczce si niezale偶nie od siebie, po jednym naraz.

2. Miary wydajnoci:
 Dobrym sposobem oceny modelu jest wykorzystanie sprawdzianu krzy偶owego. Zastosujemy funkcj cross_val_score() do oceny naszego modelu SGDClassifier za pomoc metody sprawdzianu krzy偶owego, wygenerujemy trzy podzbiory.

  Wa偶na Uwaga

>[!important]
> Kroswalidacja k-krotna oznacza rozdzielenie zestawu uczcego si na k podzbior贸w ( w naszym przypadku na 3), nastpnie wyuczany jest model k razy. W ka偶dej iteracji, jeden z podzbior贸w jest u偶ywany jako zestaw testowy, podczas gdy pozostae k-1 podzbiory s u偶ywane do treningu modelu.

```python
from sklearn.model_selection import cross_val_score  

cross_val_scores = cross_val_score(sgd_clf, X_train, y_train_binary, cv=3, scoring="accuracy")  
print(f'Dokadno (kroswalidacja SGD): {cross_val_scores}')
```

>  [0.95035 0.96035 0.9604 ]

Jednak ten spos贸b oceny nie sprawdza si tak dobrze w przypadku gdy niekt贸re klasy wystpuj znacznie czciej od pozostaych tzw. klasy wypaczone.

Innym sposobem oceny wydajnoci klasyfikatora jest  macierz pomyek.

```

            Przewidywana
                1      0
              +----+----+
         1    | TP | FN |
Rzeczywista   +----+----+
         0    | FP | TN |
              +----+----+

```
   
Macierz pomyek pozwala zrozumie, w jaki spos贸b model popenia bdy:

- **Wysokie wartoci TP** wskazuj, 偶e model dobrze klasyfikuje pozytywne przypadki.
- **Wysokie wartoci TN** wskazuj na dobry poziom klasyfikacji negatywnych przypadk贸w.
- **Wysokie wartoci FP** wskazuj, 偶e model czsto myli negatywne przypadki z pozytywnymi.
- **Wysokie wartoci FN** wskazuj, 偶e model czsto przeocza pozytywne przypadki.


```python
from sklearn.metrics import accuracy_score, confusion_matrix 
from sklearn.model_selection import cross_val_predict
import seaborn as sns

# Kroswalidacja z przewidywaniami  
y_pred_cv = cross_val_predict(sgd_clf, X_train, y_train_binary, cv=3)  
accuracy = accuracy_score(y_train_binary, y_pred_cv)  
print(f'Dokadno klasyfikatora (kroswalidacja): {accuracy:.2f}')  
  
confusion_mat = confusion_matrix(y_train_binary, y_pred_cv)  
  
# Wywietlenie macierzy pomyek  
plt.figure(figsize=(8, 6))  
sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])  
plt.ylabel('Rzeczywista')  
plt.xlabel('Przewidywana')  
plt.title('Macierz Pomyek')  
plt.show()
```

> Dokadno klasyfikatora (kroswalidacja): 0.96

![[Macierz.png]]
 Wa偶na Uwaga

>[!important]
>Ka偶dy rzd macierzy pomyek reprezentuje klas rzeczywista. Natomiast kolumna stanowi przewidywan klas. Interpretacja 53892 stanowi prawidowo sklasyfikowane pr贸bki niebdce pitkami tzw. PN, 687 przykad贸w zostao niewaciwe uznane za 5, tzw. FP (bd pierwszego rodzaju). 
W drugim rzdzie zostay umieszczone obrazy zaklasyfikowane jako pitki.
Przy czym 1891 pr贸bek zostao nieprawidowo sklasyfikowanych jako niebdce pitkami tzw. FN natomiast 3530 zostao prawidowo zaklasyfikowane jako 5. 

>Nasz doskonay klasyfikator uzyskiwaby wycznie przykady prawdziwe pozytywne i prawdziwe negatywne () na g贸wnej przektnej miaby niezerowe wartoci. 

Jeszcze inne miary:

3. Peno 

**Peno** (znana r贸wnie偶 jako **czuo**) jest to odsetek pozytywnych przykad贸w prawidowo rozpoznane przez klasyfikator.
$$ \text{Peno} = \frac{TP}{TP + FN} $$


- \( TP \ (True Positives) - liczba rzeczywistych pozytywnych przypadk贸w, kt贸re zostay poprawnie sklasyfikowane przez model.
- \( FN \ (False Negatives) - liczba rzeczywistych pozytywnych przypadk贸w, kt贸re model bdnie sklasyfikowa jako negatywne.

4. F1 
Jest to rednia harmoniczna precyzji z penoci.  Jak to rozumie?
Standardowa rednia traktuje wszystkie wartoci jednakowo, natomiast rednia harmoniczna nadaje wiksz wag maym wartoci.
 $$ F1 = 2 \cdot \frac{\text{Precyzja} \cdot \text{Peno}}{\text{Precyzja} + \text{Peno}} $$ Gdzie: - **Precyzja** (Precision) to miara, kt贸ra okrela, jak wiele z przewidywanych pozytywnych przypadk贸w jest rzeczywicie pozytywnych.
 $$ \text{Precyzja} = \frac{TP}{TP + FP} $$
```python

from sklearn.metrics import precision_score, recall_score, f1_score  

precision = precision_score(y_train_binary, y_pred_cv) 
recall = recall_score(y_train_binary, y_pred_cv) 
f1 = f1_score(y_train_binary, y_pred_cv)

print(f'Precyzja: {precision:.2f}') 
print(f'Peno: {recall:.2f}') 
print(f'F1-score: {f1:.2f}')
```

>Precyzja: 0.84
>Peno: 0.65
>F1-score: 0.73

  Wa偶na Uwaga Kompromis pomidzy precyzj a penoci
 
>[!important]
>Przy czym F1 faworyzuje klasyfikatory majce zbli偶one wartoci precyzji i penoci. Nie zawsze tego chcemy, przykadowo majc na celu wyuczenie klasyfikatora w okrelaniu bezpiecznych film贸w dla dzieci bardziej zale偶aoby nam na tym by klasyfikator odrzuca wiele dobrych film贸w (maa warto penoci), ale zapamitywaby jedynie bezpieczne (du偶a precyzja). Niekorzystna byaby relacja odwrotna gdzie model cechowaby si du偶o wiksz penoci, ale dopuszczaby kilka nieodpowiednich film贸w.
Jednak przy trenowaniu klasyfikatora do wykrywania zodziei z zapisu kamer prawdopodobnie nic zego by si nie stao gdyby model mia przykadowo 30% precyzji przy 99% penoci. W贸wczas mo偶e i byoby kilka faszywych alarm贸w ale niemal wszyscy przestpcy zostaliby zapani.
### Klasyfikacja wieloetykietowa

Do tej pory ka偶dy przykad by przydzielany wycznie do jednej klasy. Jednak we藕my przykad rozpoznawania twarzy, co powinien zrobi gdy na zdjciu jest wiele os贸b? 
Powinien przydzieli po jednej etykiecie na ka偶d rozpoznan twarz. Za贸偶my ,偶e model zosta wyuczony do rozpoznania grupy przyjaci贸 na zdjciu: Tomka, Piotrka i Agnieszki. Po zaprezentowaniu zdj Tomka i Piotrka powinien zosta wygenerowany wynik [True, True, False ].

Tego typu system klasyfikujcy zdolny do wyznaczania wielu binarnych znacznik贸w nosi nazw klasyfikacji wieloetykietowej. 